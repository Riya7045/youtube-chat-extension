# -*- coding: utf-8 -*-
"""
RAG with LangChain, Gemini Pro API, and FAISS Vector Store
Wrapped as a single callable function.
"""

from youtube_transcript_api import YouTubeTranscriptApi, TranscriptsDisabled, NoTranscriptFound, _errors
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI
from langchain_community.vectorstores import FAISS
from langchain_core.prompts import PromptTemplate
from langchain_core.runnables import RunnableParallel, RunnablePassthrough, RunnableLambda
from langchain_core.output_parsers import StrOutputParser
from dotenv import load_dotenv
import os

def load_api_key():
    load_dotenv()
    api_key = os.getenv("GEMINI_API_KEY")
    if not api_key:
        raise ValueError("GEMINI_API_KEY not found in environment variables.")
    return api_key


def fetch_transcript(video_id: str) -> str:
    """Fetch transcript text from a YouTube video ID."""
    try:
        ytt_api = YouTubeTranscriptApi()
        # Store the transcript language (generated of manually written) in a variable
        transcript_language = ytt_api.list(video_id).find_transcript(['en', 'hi','ar', 'zh-Hant', 'nl', 'fr', 'de', 'hi', 'id', 'it', 'ja', 'ko', 'pt', 'ru', 'es', 'th', 'uk', 'vi']).language_code

        if transcript_language == 'en':
            transcript_list = ytt_api.fetch(video_id, languages=['en']).to_raw_data()
            return " ".join(chunk["text"] for chunk in transcript_list)
        elif transcript_language == 'hi':
            transcript_list = ytt_api.fetch(video_id, languages=['hi']).to_raw_data()
            # Write code to translate into english from hindi
            return " ".join(chunk["text"] for chunk in transcript_list)
        else:
            transcript_list = ytt_api.fetch(video_id).to_raw_data()
            # Write code to translate into english from whatever language it is in
            return " ".join(chunk["text"] for chunk in transcript_list)
        
    except (TranscriptsDisabled, NoTranscriptFound):
        print("No captions available for this video.")
        return ""
    except Exception as e:
        print(f"Error fetching transcript: {e}")
        return ""



def build_vector_store(chunks, api_key: str):
    """Embed text chunks using Gemini embeddings and store them in FAISS."""
    embeddings = GoogleGenerativeAIEmbeddings(
        model="models/embedding-001",
        google_api_key=api_key
    )
    return FAISS.from_documents(chunks, embeddings)

def format_docs(retrieved_docs):
    """Format retrieved document chunks into a single string context."""
    return "\n\n".join(doc.page_content for doc in retrieved_docs)

def generate_answer(input_dict: dict) -> str:
    """
    Runs the full RAG pipeline with Gemini Pro API, LangChain, and FAISS 
    for the given query and YouTube video ID.
    
    input_dict keys:
      - 'query': Question string
      - 'videoId': YouTube video ID string (e.g. "lIHE9NVpBoI")
    
    Returns:
      - Answer string generated by the Gemini LLM
    """
    api_key = load_api_key()

    query = input_dict.get('query', '')
    video_id = input_dict.get('videoId', '')
    if not query:
        return "Error: 'query' missing or empty."
    if not video_id:
        return "Error: 'videoId' missing or empty."

    # Step 1a: Document Ingestion (fetch transcript)
    transcript = fetch_transcript(video_id)
    if not transcript:
        return "No transcript available for this video."

    # Step 1b: Text splitting
    splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    chunks = splitter.create_documents([transcript])

    # Step 1c/1d: Embedding & vector store build
    vector_store = build_vector_store(chunks, api_key)

    # Step 2: Retrieval (top-4 by similarity)
    retriever = vector_store.as_retriever(search_type="similarity", search_kwargs={"k": 4})
    retrieved_docs = retriever.invoke(query)

    if not retrieved_docs:
        return "No relevant documents found for the query."

    # Step 3: Augmentation (prompt preparation)
    prompt = PromptTemplate(
        template="""
You are a helpful assistant and are basically a youtube AI assistant chrome extension who have a script/transcript of a youtube video given below. 
Answer ONLY from the provided transcript context.
If the context is insufficient, just say you don't know. Also do not say that text don't contain the sufficient data instead try to frame the sentence in such a way that you from backend have watched the whole youtube video for the user and you haven't found anything that provides context for user's query.
Important: Convert all the text in english and responde in english only.
Context: {context}
QuerySo: {question}
""",
        input_variables=['context', 'question']
    )

    context_text = format_docs(retrieved_docs)
    final_prompt = prompt.invoke({"context": context_text, "question": query})

    # Step 4: Generation (Gemini LLM)
    llm = ChatGoogleGenerativeAI(
        model="gemini-2.5-flash",
        google_api_key=api_key,
        temperature=0.2
    )

    answer = llm.invoke(final_prompt)

    # # Step 6: Cleanup (optional)
    # try:
    #     del retriever
    #     del vector_store
    #     del llm
    # except Exception as e:
    #     print(f"Cleanup warning: {e}")

    return answer.content


# # Example usage:
# response = generate_answer({
#   "query": "iss video me kya baat ho rhi hai",
#   "videoId": "HeAGWTgi4sU"
# })
# print(response)
